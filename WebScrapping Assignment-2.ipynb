{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3270c0c",
   "metadata": {},
   "source": [
    "# WebScrapping Using \"SELENIUM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec70916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bde9428",
   "metadata": {},
   "source": [
    "#### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70053164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hifzu\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\hifzu\\anaconda3\\lib\\site-packages (from selenium) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "# installing selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d55e234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "385a555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting web driver\n",
    "driver= webdriver. Chrome(r'C:\\Users\\hifzu\\Downloads\\chromedriver.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bfe1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "link= \"https://www.naukri.com\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2eaef526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"9589b4ad24f6b2a44a603a9f0bd27373\", element=\"f595c2ae-2468-4203-89be-c0d0226173b1\")>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key= driver.find_element_by_id('qsb-keyword-sugg')\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd8854c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding text in  job search bar\n",
    "key.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e42bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding text in location search bar\n",
    "loc= driver.find_element_by_xpath(\"//input[@placeholder='Enter Locations…']\")\n",
    "loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43059414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on \"Search\"\n",
    "search= driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627a14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11bdc84e",
   "metadata": {},
   "source": [
    " Scrapping 10 JOB Title from the output page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc5f8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "name= driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4e2397e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Executive Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst - I/II',\n",
       " 'Hiring For the role - DATA Analyst (Flipkart)',\n",
       " 'Hiring For the role - DATA Analyst (Flipkart)',\n",
       " 'Business Data Analyst - MIS & Reporting',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Associate, Data Hierarchy Analyst( MDM)',\n",
       " 'Product Data Analyst']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name=[]\n",
    "for k in name:\n",
    "    Name.append(k.text)\n",
    "Name[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f416e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a7e69a7",
   "metadata": {},
   "source": [
    "Scrapping first 10 job locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7eb46b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2aace599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Bellandur)\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru(Bellandur)\\n(WFH during Covid)',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loc=[]\n",
    "for k in loc:\n",
    "    Loc.append(k.text)\n",
    "Loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67aee3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "321f0764",
   "metadata": {},
   "source": [
    "Scrapping first 10 company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f12f5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "com= driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1045a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gokaldas Exports Ltd',\n",
       " 'Virtusa Consulting Services Pvt Ltd',\n",
       " 'Philips India Limited',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'INTERTRUST GROUP',\n",
       " 'Flipkart',\n",
       " 'Flipkart',\n",
       " 'GENPACT India Private Limited',\n",
       " 'Trifacta']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Com=[]\n",
    "for k in com:\n",
    "    Com.append(k.text)\n",
    "Com[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af00849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72fc72b1",
   "metadata": {},
   "source": [
    "Scrapping 10 \"job experience required\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93da2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d89a5feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Yrs',\n",
       " '8-12 Yrs',\n",
       " '3-6 Yrs',\n",
       " '1-6 Yrs',\n",
       " '1-6 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-3 Yrs',\n",
       " '3-8 Yrs',\n",
       " '1-3 Yrs',\n",
       " '2-5 Yrs']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp=[]\n",
    "for k in exp:\n",
    "    Exp.append(k.text)\n",
    "Exp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504e4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f981c418",
   "metadata": {},
   "source": [
    "Creating DataFrame of searched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d15200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Company-Name</th>\n",
       "      <th>Experience-Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Executive Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gokaldas Exports Ltd</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...</td>\n",
       "      <td>Virtusa Consulting Services Pvt Ltd</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - I/II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For the role - DATA Analyst (Flipkart)</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)\\n(WFH during Co...</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For the role - DATA Analyst (Flipkart)</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)\\n(WFH during Co...</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Data Analyst - MIS &amp; Reporting</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>INTERTRUST GROUP</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Associate, Data Hierarchy Analyst( MDM)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Trifacta</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job-Title  \\\n",
       "0                          Executive Data Analyst   \n",
       "1                             Senior Data Analyst   \n",
       "2                             Data Analyst - I/II   \n",
       "3   Hiring For the role - DATA Analyst (Flipkart)   \n",
       "4   Hiring For the role - DATA Analyst (Flipkart)   \n",
       "5         Business Data Analyst - MIS & Reporting   \n",
       "6                             Senior Data Analyst   \n",
       "7                             Senior Data Analyst   \n",
       "8  Senior Associate, Data Hierarchy Analyst( MDM)   \n",
       "9                            Product Data Analyst   \n",
       "\n",
       "                                        Job-Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Bangalore/Bengaluru(Bellandur)\\n(WFH during Co...   \n",
       "4  Bangalore/Bengaluru(Bellandur)\\n(WFH during Co...   \n",
       "5                        Mumbai, Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                          Company-Name Experience-Required  \n",
       "0                 Gokaldas Exports Ltd             0-3 Yrs  \n",
       "1  Virtusa Consulting Services Pvt Ltd            8-12 Yrs  \n",
       "2                Philips India Limited             3-6 Yrs  \n",
       "3     Allegis Services India Pvt. Ltd.             1-6 Yrs  \n",
       "4     Allegis Services India Pvt. Ltd.             1-6 Yrs  \n",
       "5                     INTERTRUST GROUP             3-8 Yrs  \n",
       "6                             Flipkart             2-3 Yrs  \n",
       "7                             Flipkart             3-8 Yrs  \n",
       "8        GENPACT India Private Limited             1-3 Yrs  \n",
       "9                             Trifacta             2-5 Yrs  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Search_result=pd.DataFrame({})\n",
    "Search_result['Job-Title']=Name[:10]\n",
    "Search_result['Job-Location']=Loc[:10]\n",
    "Search_result['Company-Name']=Com[:10]\n",
    "Search_result['Experience-Required']=Exp[:10]\n",
    "Search_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12706c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f6b2cc6",
   "metadata": {},
   "source": [
    "#### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9657257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8a4a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting web driver\n",
    "driver= webdriver. Chrome(r'C:\\Users\\hifzu\\Downloads\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf41602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking webpage to web driver\n",
    "link= \"https://www.naukri.com\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c76c393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"e5801924288df7fdf7b2a10af8fb15d4\", element=\"97a3de79-e5ac-4bf2-be32-495ee04a5092\")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword= driver.find_element_by_xpath(\"//input[@placeholder='Skills, Designations, Companies']\")\n",
    "keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b2ccab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding text in  job search bar\n",
    "keyword.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ce553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding text in location search bar\n",
    "loc= driver.find_element_by_xpath(\"//input[@placeholder='Enter Locations…']\")\n",
    "loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447aa9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on \"Search\"\n",
    "search= driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a151a9",
   "metadata": {},
   "source": [
    "Scrapping JOB Title from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf601f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name= driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3defff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "for k in name:\n",
    "    Name.append(k.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15394f",
   "metadata": {},
   "source": [
    "Scrapping job locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab252a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d7db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loc=[]\n",
    "for k in loc:\n",
    "    Loc.append(k.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f6301",
   "metadata": {},
   "source": [
    "Scrapping Companies Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd9ecd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "com= driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b517f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Com=[]\n",
    "for k in com:\n",
    "    Com.append(k.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce1f93",
   "metadata": {},
   "source": [
    "Scrapping Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f4379f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting links of all pages\n",
    "link= driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accb262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_link=[]\n",
    "for k in link:\n",
    "    job_link.append(k.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83cbaaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d159b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7869f1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Responsibilities include: Defining and evaluating key metrics and understanding what moves them and why Ownership of conceptualizing, developing, and maintaining dashboards and visualizations Investigating evolving fraud trends to extract patterns, identify root causes and propose actionable solutions Communicating analyses and recommendations to cross functional stakeholders for decision making Empowering the team to answer data questions quickly and easily by building high-quality ground truth data sets Here are example traits we value: Professional industry experience in a quantitative analysis role (7+ years preferred) Comfortable in SQL and some experience with a programming language (Python or R a plus) Ability to communicate clearly and effectively to cross functional partners of varying technical levels Ability to define relevant metrics that can guide and influence stakeholders to the appropriate and accurate insights Experience or willingness to learn tools to create data pipelines using Airflow Building clear and easy to understand dashboards (Tableau) and presentations',\n",
       " '  Skills Required Skills: Data Science, Machine Learning, Deep Learning, Python, NLP Desired Skills: Computer Vision Roles and responsibilities Experience in Data Modelling, R, Python, SQL, Data Science, Machine Learning, Deep Learning, NLP, Statistics Have ability to solve Business problems using Data Should possess extensive knowledge of and experience in applying data mining and machine learning techniques on large amount of datasets High level of proficiency in statistical tools like R, Python Candidate will be expected to communicate analytical results in a way that is meaningful for business stakeholders and provides actionable insights. Have the ability to discover new opportunities where advanced analytical techniques can be leveraged for solving business problems Good to Have Expertise in programming languages like Java/C/C /Python Experience with relational databases and SQL is good to have Experience in audio and video analytics Relevant experience in Big Data platforms like Hadoop eco-system Come up with innovative algorithms and solutions Staffing Type:Permanent',\n",
       " 'Required Technical and Professional Expertise • 6+ years of industry work experience in data scientist projects • Master’s degree or higher in Statistics/Math/Computer Science or related field • Background in applied statistical modeling on large experimental or observational data sets • Experience extracting data from a variety of sources, and a desire to expand those skills (working knowledge SQL is required, Spark is a plus) • Experience with one or more statistical or machine learning software such as R, Python, etc. • Must showcase past work through published articles/GitHub/social media  Preferred Technical and Professional Expertise • Knowledge of distributed computing systems, e.g. Cosmos, Spark, Hadoop, and relational database management system • PhD. in Statistics is preferred • You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies • Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work • Intuitive individual with an ability to manage change and proven time management • Proven interpersonal skills while contributing to team effort by accomplishing related results as needed',\n",
       " 'Department- BIRS (Business Intelligence Risk Solutions)  JD Statistical Analyst/ Data scientist: Client oriented approach to problem solving. Individual should be able to have a holistic view of multiple businesses and develop analytic solutions accordingly. Own and deliver multiple and complex analytic projects. This would require an understanding of business context, conversion of business problems in modeling, and implementing such solutions to create business value. Always up to date with the latest use cases of modeling community, machine learning and deep learning algorithms and share knowledge within the team. Proficiency in basic statistics, hypothesis testing, segmentation and predictive modeling. Ability to translate and articulate technical thoughts and ideas to a larger audience including influencing skills with peers and senior management. Strong project management skills. Ability to coach and mentor juniors. Eagerness to work on new and challenging tasks on a regular basis with an ability to research new ways of doing things better/efficiently. Contribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc. Basic Qualifications  Bachelor’s Degree with 2+ years of experience in data analytics, Hands-on experience in Python / SAS or R programing along with strong experience in SQL and Excel Macros. Experienced in working with large and multiple datasets, data warehouses and ability to pull data using relevant programs and coding. Well versed with necessary data preprocessing and feature engineering skills. At least 2 years of experience implementing Machine learning algorithms such as Random Forest and Gradient Boosting in solving business problems such as Default classification and macroeconomic forecasting. At least 1 year of experience implementing deep learning techniques like neural networks Exposure to deep learning packages like Tensorflow Strong background in Statistical Analysis Background in BFSI space will be preferredRoles and Responsibilities  If anyone interested, please share your resume to below mail id:-  Soundarya.s@manpower.co.in;',\n",
       " 'Use predictive modeling to increase and optimize customer experiences, revenue generation, campaign optimization and other business outcomes Work with product management to develop data use cases and embed predictive models in workflows on resource constrained platforms and cloud enabled. Selecting features, building and optimizing classifiers using machine learning and deep learning techniques Collaborates with Data Engineers to enhance data collection and ingestion/curation techniques to include information that is relevant for building analytic systems Processing, cleansing, and verifying the integrity of data used for analysis Develop processes and tools to monitor and analyze model performance and data accuracy. Life cycle management of predictive models. Adherence to compliance procedures in accordance with regulatory standards, requirements, and policies. Managing and designing the reporting environment, including data sources security, and metadata. Job Qualifications: Master s degree or PhD in Computer Science, Information management, Statistics or related field, with 3 to 5 years of experience in the Consumer or Healthcare industry manipulating data sets and building predictive models with focus on product development Experience in statistical modelling, machine learning, data mining, unstructured data analytics and natural language processing. Sound understanding of - Bayesian Modelling, Classification Models, Cluster Analysis, Neural Network, Nonparametric Methods, Multivariate Statistics, etc. Strong hands on knowledge of ML techniques like regression algorithms, K-NN, Na ve Bayes, SVM and ensemble techniques like Random forest, AdaBoost etc Having strong knowledge in unsupervised learning algorithms using Neural networks and Deep-Learning Strong knowledge in Data Wrangling and Exploration techniques to identify the patterns, trends and outliners. Deep knowledge and practical experience with data science toolkits, such as NumPy, Pandas, scikit-learn or equivalent Experience with data visualization tools, such as QlikView, Matplotlib, seaborn or equivalent tools. Proficiency in using query languages, such as SQL, PL/SQL Hands on experience in the one or more databases like Hadoop, AWS Redshift, Snowflake etc. Good applied statistics skills, such as distributions, statistical testing, regression, etc. Good ETL scripting and programming skills, such as Python, R or Scala to integrate developed solution into the proposition. A team player capable of working and integrating across cross-functional team for implementing project requirements. Experience in technical requirements gathering and documentation. Ability to work effectively and independently in a fast-paced global collaborative agile team environment with tight deadlines A flexible, pragmatic and collaborative team player with innate ability to engage with stakeholders at all levels in the organization. A self-starter with high levels of drive, energy, resilience and a desire for professional excellence with a passion for data and data science',\n",
       " \"Job description:  Seeking senior data scientists for project-based roles that involve working on various projects.  The candidate must have experience in Python coding language and machine learning. The candidate will be working on a part-time basis and hours will be flexible based on the candidate's availability. Opportunity to grow in a startup setting. What you'll need: B.Tech in CS or Statistics with demonstrable experience of over 5 years through publications/deployed solutions/projects. M.Tech or Ph.D. in CS or Statistics with demonstrable experience of over 3 years through publications/deployed solutions/projects. A deep understanding of applied statistical analysis and predictive modeling is desired. The candidate must have a thorough grasp of the theory and application of broad ML algorithms namely, but not limited to regression, SVM, Tree, Random Forests, Boosting, Neural Network, clustering, forecasting, deep learning, text analysis, etc. It is not expected that the candidate has actually worked on all these modules. Strong proficiency in Python or R is necessary\",\n",
       " 'Roles and Responsibilities We are looking for someone who would be responsible for analyzing data and providing business insights. As a Data Scientist your responsibilities will include understanding the business problem and experimenting with different modelling architectures to create the best possible setup from model performance as well as computational performance. To do this job successfully, you need exceptional skills in Machine Learning and Programming. Your ultimate goal will be to find the best data-based solution for the problem at hand. Moreover, you are expected to learn fast and deliver quickly in a fast-paced startup environment. If you thrive on ambiguity and are a problem solver and yet deliver value to clients, feel free to reach out to us. We are looking ONLY FOR SELF DRIVEN INDIVIDUALS with a desire to excel in Data Science Domain. Understanding business objectives and developing models that help to achieve them, along with metrics to track their progress Develop and maintain robust data processing pipelines and reproducible modeling pipelines Build mathematical models to solve various problems ranging from Time Series forecasting to Neural Networks and ensure seamless deployment in production pipelines. Analyze experimental results, iterate and refine models to create significant business impact Follow strict coding standards and other software engineering best practices   Desired Candidate Profile Proven experience as a Data Scientist or similar role Strong SQL, R/Python Skills Should have familiarity with Machine Learning Models and fundamentals in Forecasting and Optimization Techniques Should have strong mathematical background & analytical bent of mind Strong Problem-Solving Ability Ability to communicate well in a highly collaborative team environment, consisting of both technical and non-technical personnel Reliable self-starter that is capable of working with a high degree of autonomy   Perks and Benefits  NeenOpal is a global management consulting firm with a unique and specialized focus on Data Science. We provide services across the whole value chain of an organization - Digital Strategy, Sales & Marketing, Supply Chain & Logistics as well as Finance. Youll have a blast doing it in our fun, passionate environment.',\n",
       " 'Hi,  We at Prescience www.prescienceds.com looking for Data Scientist @ Bangalore .  Roles and Responsibilities As a Data Scientist you will be working with senior management of clients to understand the business requirements, define right problem statement and come up with a framework for the solution. You will also work on the solution and at time guide a small team to deliver the same. Part of job role would be develop products in the area of Natural Language Processing, Conversational Interfaces, Text Mining etc.  Desired Candidate Profile What we are looking for: Good applied statistics skills, such as distributions, statistical testing, regression, etc. Experience in Natural Language Processing, Computer Vision. Exposure to common data science business problems like clustering, classification, anomaly detection, prediction etc. Good understanding of machine learning techniques and algorithms Experience with common data science toolkits Python, R, SAS Proficiency in using query languages such as SQL, Hive, etc Experience with NoSQL database, SQL Server, PostgreSQL, MongoDB Great communication skills Data-oriented personality and excellent business analysis skills Experience in solutioning for data science related problems, work with business stakeholders to define right problem statement and solution. Open to professionals who have data analytics / BI background and then moved to Data Scientist roles.  Perks and Benefits',\n",
       " 'CRISIL (formerly Credit Rating Information Services of India Limited) is an Indian analytical company providing ratings, research, and risk and policy advisory services and is a subsidiary of American company S&P Global  We are looking Data Scientist for Mumbai & Bangalore location Candidates who can join immediately or within 30-45 need only apply  Please refer below JD for your reference-  Job Description Data scientist: Client oriented approach to problem solving. Individual should be able to have a holistic view of multiple businesses and develop analytic solutions accordingly. Own and deliver multiple and complex analytic projects. This would require an understanding of business context, conversion of business problems in modeling, and implementing such solutions to create business value. Always up to date with the latest use cases of modeling community, machine learning and deep learning algorithms and share knowledge within the team. Proficiency in basic statistics, hypothesis testing, segmentation and predictive modeling. Ability to translate and articulate technical thoughts and ideas to a larger audience including influencing skills with peers and senior management. Strong project management skills. Ability to coach and mentor juniors. Eagerness to work on new and challenging tasks on a regular basis with an ability to research new ways of doing things better/efficiently. Contribute to organizational initiatives in wide ranging areas including competency development, training, organizational building activities etc. Skills  Basic Qualifications  Bachelors Degree with 2+ years of experience in data analytics, Hands-on experience in Python / SAS or R programing along with strong experience in SQL and Excel Macros. Experienced in working with large and multiple datasets, data warehouses and ability to pull data using relevant programs and coding. Well versed with necessary data preprocessing and feature engineering skills. At least 2 years of experience implementing Machine learning algorithms such as Random Forest and Gradient Boosting in solving business problems such as Default classification and macroeconomic forecasting. At least 1 year of experience implementing deep learning techniques like neural networks Exposure to deep learning packages like Tensorflow Strong background in Statistical Analysis Background in BFSI space will be preferred',\n",
       " 'Roles and Responsibilities Job Description: Develop data powered insights deriving from distributed, real time streaming applications, and develop AI systems leveraging on such data powered insights. Looking for candidates with passion and energy to work in a high energy team with entrepreneurial culture: Self starter attitude, quick learning aptitude, passion and willingness to deliver on time with quality.  Job Skills Required: Expert data science skills using supervised and unsupervised learning. Deep learning. Compute: Spark/Storm/NiFi/Flink/Redis, or other. Visualization: Banana UI, Kibana, or other, Tools: H2O, TensorFlow, Mlib, Scikit, Keras or other. Messaging: Kafka, RabbitMQ, or other.  Strong Analytical and Math/Statistics skills.  Qualification : M.Tech/M.E./M.S. in Computer Science, Engineering or a related field, preferably with a concentration, major or minor in Data Science or Machine Learning. PhD would be added advantage.  Desired Candidate Profile Desirable s that would strengthen candidacy:  Proven track record from public competitions such as from Kagel, Analytics Vidya, etc.   Expertise in one or more high level programming languages such as Java, Scala, Python, Go, Erlang, etc.  Expertise in developing scalable applications in a distributed environment.  Strong SQL or NoSQL skills with one or more open source DBMS such as MySql, MongoDB, Cassandra.  Expertise in containerized environments on private or public clouds - Aws Azure, etc.',\n",
       " 'Roles and Responsibilities Job Description: Develop data powered insights deriving from distributed, real time streaming applications, and develop AI systems leveraging on such data powered insights. Looking for candidates with passion and energy to work in a high energy team with entrepreneurial culture: Self starter attitude, quick learning aptitude, passion and willingness to deliver on time with quality.  Job Skills Required: Expert data science skills using supervised and unsupervised learning. Deep learning. Compute: Spark/Storm/NiFi/Flink/Redis, or other. Visualization: Banana UI, Kibana, or other, Tools: H2O, TensorFlow, Mlib, Scikit, Keras or other. Messaging: Kafka, RabbitMQ, or other.  Strong Analytical and Math/Statistics skills.  Qualification : M.Tech/M.E./M.S. in Computer Science, Engineering or a related field, preferably with a concentration, major or minor in Data Science or Machine Learning. PhD would be added advantage.  Desired Candidate Profile Desirable s that would strengthen candidacy:  Proven track record from public competitions such as from Kagel, Analytics Vidya, etc.   Expertise in one or more high level programming languages such as Java, Scala, Python, Go, Erlang, etc.  Expertise in developing scalable applications in a distributed environment.  Strong SQL or NoSQL skills with one or more open source DBMS such as MySql, MongoDB, Cassandra.  Expertise in containerized environments on private or public clouds - Aws Azure, etc.',\n",
       " 'Dear Candidate,  Warm greetings from SP Staffing Services.  We are hiring Data Science / ML Resources for our Client.  Role: Sr. Data Scientist - Machine Learning Exp: 10 to 15 yrs Location: Pune, Bangalore, Chennai  Requisite:  Ideal Resource should have 10+ years of experience in Data Science Machine Learning.  Responsibilities:  Design and Develop ML / NLP models for the project requirement Deliver ownership to setup ML / NLP models with respect to tools, data and infrastructure as required Work closely with Product Owner and Product architect right from ML based solution conceptualization till implementation in response to a client requirement Thought leadership on building ML/NLP based solution based on client requirements Lead the ML / NLP dialogue during the customer visits and other partner events  Required Skills:  Strong knowledge of Machine Learning / NLP algorithms Information extraction, named entity recognition, text clustering, Knowledge Graph, text summarization, intent classification, word embeddings, vector space models Strong experience in NLP using Python Experience in developing Microservices and web services Understanding of data and data analysis, manage Large Data Sets Sound exposure on Pandas, Scikit and Numpy Min 4+ years of experience implementing and deploying machine learning and deep learning frameworks (Spark, TensorFlow, Keras, Caffe, etc.) Application programming in cloud platforms including Azure, IBM, AWS and GCP Hands on experience Data Science / Big Data technology and architecture']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Des=[]\n",
    "for k in job_link:\n",
    "    driver.get(k)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        content= driver.find_element_by_xpath(\"//div[@class='dang-inner-html']\").text.replace('\\n',\" \").replace('\\n\\n',\" \")\n",
    "    \n",
    "        Des.append(content)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827fcf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb0abb0d",
   "metadata": {},
   "source": [
    "Creating DataFrame of 10 searched job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54fb2e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Company-Name</th>\n",
       "      <th>Job-Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Scientist BFSI</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Responsibilities include: Defining and evaluat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Skills Required Skills: Data Science, Machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Required Technical and Professional Expertise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Happiest Minds Technologies Pvt.Ltd</td>\n",
       "      <td>Department- BIRS (Business Intelligence Risk S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist (Python &amp; SQL)</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>Use predictive modeling to increase and optimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Scientist / Statistical Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ManpowerGroup Services India Private Limited</td>\n",
       "      <td>Job description:  Seeking senior data scientis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Roles and Responsibilities We are looking for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Hi,  We at Prescience www.prescienceds.com loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>CRISIL (formerly Credit Rating Information Ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Freelance Data Scientist Project Based</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Shikvix</td>\n",
       "      <td>Roles and Responsibilities Job Description: De...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job-Title  \\\n",
       "0                         Lead Data Scientist BFSI   \n",
       "1               Data Scientist: Advanced Analytics   \n",
       "2                            Senior Data Scientist   \n",
       "3                            SENIOR DATA SCIENTIST   \n",
       "4                    Data Scientist (Python & SQL)   \n",
       "5  Hiring For Data Scientist / Statistical Analyst   \n",
       "6                                Sr Data Scientist   \n",
       "7                                Sr Data Scientist   \n",
       "8                         Associate Data Scientist   \n",
       "9           Freelance Data Scientist Project Based   \n",
       "\n",
       "                                        Job-Location  \\\n",
       "0                                Bengaluru/Bangalore   \n",
       "1                                Bengaluru/Bangalore   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bengaluru/Bangalore   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                             Remote   \n",
       "\n",
       "                                   Company-Name  \\\n",
       "0                        IBM India Pvt. Limited   \n",
       "1                        IBM India Pvt. Limited   \n",
       "2                                        Airbnb   \n",
       "3           Happiest Minds Technologies Pvt.Ltd   \n",
       "4                                  AVE-Promagne   \n",
       "5  ManpowerGroup Services India Private Limited   \n",
       "6                        IBM India Pvt. Limited   \n",
       "7                        IBM India Pvt. Limited   \n",
       "8                         Philips India Limited   \n",
       "9                                       Shikvix   \n",
       "\n",
       "                                     Job-Description  \n",
       "0  Responsibilities include: Defining and evaluat...  \n",
       "1    Skills Required Skills: Data Science, Machin...  \n",
       "2  Required Technical and Professional Expertise ...  \n",
       "3  Department- BIRS (Business Intelligence Risk S...  \n",
       "4  Use predictive modeling to increase and optimi...  \n",
       "5  Job description:  Seeking senior data scientis...  \n",
       "6  Roles and Responsibilities We are looking for ...  \n",
       "7  Hi,  We at Prescience www.prescienceds.com loo...  \n",
       "8  CRISIL (formerly Credit Rating Information Ser...  \n",
       "9  Roles and Responsibilities Job Description: De...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Search_result=pd.DataFrame({})\n",
    "Search_result['Job-Title']=Name[:10]\n",
    "Search_result['Job-Location']=Loc[:10]\n",
    "Search_result['Company-Name']=Com[:10]\n",
    "Search_result['Job-Description']=Des[:10]\n",
    "Search_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e99f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951caed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b69dda57",
   "metadata": {},
   "source": [
    "### 3. In this question you have to scrape data using the filters available on the webpage\n",
    "\n",
    "### You have to use the location and salary filter.\n",
    "### You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "### You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "### The location filter to be used is “Delhi/NCR”.\n",
    "### The salary filter to be used is “3-6” lakhs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d540b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "804ff337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f010bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting web driver\n",
    "driver= webdriver. Chrome(r'C:\\Users\\hifzu\\Downloads\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f43438e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking webpage to web driver\n",
    "link= \"https://www.naukri.com\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4043a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"942fa04342db8d4975e42c03c53b0901\", element=\"8123f5a7-19c7-415e-90c0-8d692ec7999f\")>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword= driver.find_element_by_xpath(\"//input[@placeholder='Skills, Designations, Companies']\")\n",
    "keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baeda554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding text in  job search bar\n",
    "keyword.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22185c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on \"Search\"\n",
    "search= driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20395dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Delhi/NCR\n",
    "loc_filter=driver.find_element_by_xpath(\"//span[@title='Delhi / NCR']\")\n",
    "\n",
    "loc_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08e752d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting salary range 3-6 lakhs\n",
    "sal_filter= driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "sal_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5447afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping job title:\n",
    "job=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "851ec716",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Job=[]\n",
    "for k in job:\n",
    "    Job.append(k.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e8a61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping company name:\n",
    "com=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b0bdabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Com=[]\n",
    "for k in com:\n",
    "    Com.append(k.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "abd49817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping locations name:\n",
    "loc=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eae0a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Loc=[]\n",
    "for k in loc:\n",
    "    Loc.append(k.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ced62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "282ed9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp=[]\n",
    "for k in exp:\n",
    "    Exp.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "282c46c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Company-Name</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Exp-Req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst/Data Scientist</td>\n",
       "      <td>Skillenable Fintech Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PROCESS NINE TECHNOLOGIES PVT.LTD.</td>\n",
       "      <td>Gurgaon/Gurugram\\n(WFH during Covid)</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>Noida\\n(WFH during Covid)</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - WFH - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Immediate Openings For Data Scientist For Wipr...</td>\n",
       "      <td>IDESLABS PRIVATE LIMITED</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist/ Machine Learning Engineer</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>Mohali/SAS Nagar, Hyderabad/Secunderabad, Ahme...</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kusum Healthcare Pvt. Ltd.</td>\n",
       "      <td>Delhi / NCR(Okhla)</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-Title  \\\n",
       "0  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "1                        Data Analyst/Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3  Data Scientist / Data Analyst / Business Analy...   \n",
       "4                                     Data Scientist   \n",
       "5                      Data Scientist / Data Analyst   \n",
       "6               Data Scientist - WFH - MIND Infotech   \n",
       "7  Immediate Openings For Data Scientist For Wipr...   \n",
       "8          Data Scientist/ Machine Learning Engineer   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                               Company-Name  \\\n",
       "0                 GABA Consultancy services   \n",
       "1       Skillenable Fintech Private Limited   \n",
       "2        PROCESS NINE TECHNOLOGIES PVT.LTD.   \n",
       "3                 GABA Consultancy services   \n",
       "4              R Systems International Ltd.   \n",
       "5                                    CARS24   \n",
       "6  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED   \n",
       "7                  IDESLABS PRIVATE LIMITED   \n",
       "8             Creative Hands HR Consultancy   \n",
       "9                Kusum Healthcare Pvt. Ltd.   \n",
       "\n",
       "                                        Job-Location   Exp-Req  \n",
       "0               Noida, Gurgaon/Gurugram, Delhi / NCR   0-0 Yrs  \n",
       "1  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   2-5 Yrs  \n",
       "2               Gurgaon/Gurugram\\n(WFH during Covid)   1-3 Yrs  \n",
       "3                 Noida, New Delhi, Gurgaon/Gurugram   0-0 Yrs  \n",
       "4                          Noida\\n(WFH during Covid)   3-6 Yrs  \n",
       "5                                   Gurgaon/Gurugram   1-5 Yrs  \n",
       "6  Pune, Chennai, Bangalore/Bengaluru, Delhi / NC...   3-7 Yrs  \n",
       "7                                   Gurgaon/Gurugram  5-10 Yrs  \n",
       "8  Mohali/SAS Nagar, Hyderabad/Secunderabad, Ahme...   0-0 Yrs  \n",
       "9                                 Delhi / NCR(Okhla)   4-6 Yrs  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_result=pd.DataFrame({})\n",
    "Job_result['Job-Title']=Job[:10]\n",
    "Job_result['Company-Name']=Com[:10]\n",
    "Job_result['Job-Location']=Loc[:10]\n",
    "Job_result['Exp-Req']=Exp[:10]\n",
    "Job_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f3ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b69efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abd4650c",
   "metadata": {},
   "source": [
    "### Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company. From  https://www.glassdoor.co.in/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06d31850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9cd96629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting web driver\n",
    "driver= webdriver. Chrome(r'C:\\Users\\hifzu\\Downloads\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d13b8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking webpage to web driver\n",
    "link= \" https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc087305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding text in  job search bar\n",
    "keyword= driver.find_element_by_xpath(\"//input[@aria-label='Search Keyword']\")\n",
    "keyword.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6c75f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding text in location bar\n",
    "location= driver.find_element_by_xpath(\"//input[@aria-label='Search Location']\")\n",
    "location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "53897a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on \"Search\"\n",
    "search= driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto search__SearchStyles__newSearchButton css-1dqvyh7']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a95e4",
   "metadata": {},
   "source": [
    "Scrapping Data from the searched result page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bff65650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Companies Name:\n",
    "com=driver.find_elements_by_xpath(\"//a[@class=' job-search-key-l2wjgv e1n63ojh0 jobLink']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "79f8a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "Com=[]\n",
    "for k in com:\n",
    "    Com.append(k.text.replace('\\n',\" \").replace('\\n\\n',\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b89bfebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping Posting date:\n",
    "age=driver.find_elements_by_xpath(\"//div[@data-test='job-age']\")\n",
    "len(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3029b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age=[]\n",
    "for k in age:\n",
    "    Age.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "560a9be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Rating:\n",
    "rate=driver.find_elements_by_xpath(\"//span[@class=' job-search-key-srfzj0 e1cjmv6j0']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9c0ab325",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rate=[]\n",
    "for k in rate:\n",
    "    Rate.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a51797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a225ad48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company-Name</th>\n",
       "      <th>Job-Posting</th>\n",
       "      <th>Company-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>14d</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noisy Lion</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grail Insights</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovacer</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Company-Name Job-Posting Company-Rating\n",
       "0    Liberin Technologies Private Limited        30d+            3.5\n",
       "1                          Grail Insights         24h            3.9\n",
       "2  AlgoScale Technologies Private Limited         14d            3.5\n",
       "3                              Noisy Lion         24h            3.8\n",
       "4                          Grail Insights         24h            3.3\n",
       "5            Salasar New Age Technologies        30d+            3.6\n",
       "6                                Techlive        30d+            3.8\n",
       "7                               Innovacer        30d+            3.9\n",
       "8            Salasar New Age Technologies        30d+            4.2\n",
       "9                         Newgen Software        30d+            4.1"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame:\n",
    "Job_result=pd.DataFrame({})\n",
    "Job_result['Company-Name']=Com[:10]\n",
    "Job_result['Job-Posting']=Age[:10]\n",
    "Job_result['Company-Rating']=Rate[:10]\n",
    "Job_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cba71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0babe89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e600ba2e",
   "metadata": {},
   "source": [
    "### Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "#### scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a5f3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "643a1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting web driver\n",
    "driver= webdriver. Chrome(r'C:\\Users\\hifzu\\Downloads\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "57446010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking webpage to web driver\n",
    "link= \"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "994552a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding text in  job search bar\n",
    "keyword= driver.find_element_by_xpath(\"//input[@name='sc.keyword']\")\n",
    "keyword.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1d1da89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding text in location bar\n",
    "location= driver.find_element_by_xpath(\"//input[@class='loc']\")\n",
    "location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "51fbc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on \"Search\"\n",
    "search= driver.find_element_by_xpath(\"//button[@type='submit']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a72ff8",
   "metadata": {},
   "source": [
    "Scrapping Data From the Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "df8af061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Companies Name:\n",
    "com=driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c8799e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Com=[]\n",
    "for k in com:\n",
    "    Com.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "306fd604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Number of salaries:\n",
    "num=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "026ba716",
   "metadata": {},
   "outputs": [],
   "source": [
    "Num=[]\n",
    "for k in num:\n",
    "    Num.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "479c1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping Avrage Salary:\n",
    "avrg=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "24a75d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Avrage=[]\n",
    "for k in avrg:\n",
    "    Avrage.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b771e13a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹4L',\n",
       " '₹1L',\n",
       " '₹6L',\n",
       " '₹5L',\n",
       " '₹4L',\n",
       " '₹8L',\n",
       " '₹8L',\n",
       " '₹10',\n",
       " '₹5L',\n",
       " '₹6L',\n",
       " '₹4L',\n",
       " '₹2L',\n",
       " '₹4L',\n",
       " '₹6L',\n",
       " '₹10',\n",
       " '₹8L',\n",
       " '₹10',\n",
       " '₹9L',\n",
       " '₹12',\n",
       " '₹5L']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping Minimum and Maximum Salary:\n",
    "min=driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']\")\n",
    "\n",
    "Min=[]\n",
    "\n",
    "for k in min:\n",
    "    Min.append(k.text.replace('\\n',\"\")[:3])\n",
    "    \n",
    "Min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "047e3c9f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹13L',\n",
       " '₹28L',\n",
       " '₹23L',\n",
       " '₹1Cr',\n",
       " '₹17L',\n",
       " '₹16L',\n",
       " '₹20L',\n",
       " 'L₹18L',\n",
       " '₹15L',\n",
       " '₹16L',\n",
       " '₹13L',\n",
       " '₹19L',\n",
       " '₹21L',\n",
       " '₹17L',\n",
       " 'L₹21L',\n",
       " '₹21L',\n",
       " 'L₹30L',\n",
       " '₹15L',\n",
       " 'T₹64T',\n",
       " '₹73L']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping Maximum Salary:\n",
    "min=driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']\")\n",
    "\n",
    "Max=[]\n",
    "\n",
    "for k in min:\n",
    "    Max.append(k.text.replace('\\n',\"\")[3::])\n",
    "    \n",
    "Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c1585949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping Rating of Companies:\n",
    "rate=driver.find_elements_by_xpath(\"//span[@class='m-0 css-kyx745']\")\n",
    "\n",
    "Rate=[]\n",
    "for k in rate:\n",
    "    Rate.append(k.text.replace('\\n',\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "edfd48e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company-Name</th>\n",
       "      <th>No. of Salary</th>\n",
       "      <th>Avrage Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Company-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>21 salaries</td>\n",
       "      <td>₹6,31,184 /yr</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>20 salaries</td>\n",
       "      <td>₹9,08,246 /yr</td>\n",
       "      <td>₹1L</td>\n",
       "      <td>₹28L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹11,93,390 /yr</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹23L</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>15 salaries</td>\n",
       "      <td>₹12,49,716 /yr</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹7,58,335 /yr</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹17L</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹12,80,000 /yr</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹13,55,086 /yr</td>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹20L</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹14,55,430 /yr</td>\n",
       "      <td>₹10</td>\n",
       "      <td>L₹18L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹8,86,064 /yr</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹11,10,000 /yr</td>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company-Name No. of Salary   Avrage Salary Minimum Salary  \\\n",
       "0  Tata Consultancy Services   21 salaries   ₹6,31,184 /yr            ₹4L   \n",
       "1                        IBM   20 salaries   ₹9,08,246 /yr            ₹1L   \n",
       "2                  Accenture   15 salaries  ₹11,93,390 /yr            ₹6L   \n",
       "3                  Delhivery   15 salaries  ₹12,49,716 /yr            ₹5L   \n",
       "4         Ericsson-Worldwide   14 salaries   ₹7,58,335 /yr            ₹4L   \n",
       "5         UnitedHealth Group   14 salaries  ₹12,80,000 /yr            ₹8L   \n",
       "6                      Optum   10 salaries  ₹13,55,086 /yr            ₹8L   \n",
       "7     Optum Global Solutions   10 salaries  ₹14,55,430 /yr            ₹10   \n",
       "8         Valiance Solutions   10 salaries   ₹8,86,064 /yr            ₹5L   \n",
       "9                EXL Service    9 salaries  ₹11,10,000 /yr            ₹6L   \n",
       "\n",
       "  Maximum Salary Company-Rating  \n",
       "0           ₹13L            3.9  \n",
       "1           ₹28L            3.9  \n",
       "2           ₹23L            4.1  \n",
       "3           ₹1Cr            3.8  \n",
       "4           ₹17L              4  \n",
       "5           ₹16L            3.7  \n",
       "6           ₹20L            3.7  \n",
       "7          L₹18L            3.9  \n",
       "8           ₹15L            4.2  \n",
       "9           ₹16L            3.6  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame:\n",
    "Salary_data=pd.DataFrame({})\n",
    "Salary_data['Company-Name']=Com[:10]\n",
    "Salary_data['No. of Salary']=Num[:10]\n",
    "Salary_data['Avrage Salary']=Avrage[:10]\n",
    "Salary_data['Minimum Salary']=Min[:10]\n",
    "Salary_data['Maximum Salary']=Max[:10]\n",
    "Salary_data['Company-Rating']=Rate[:10]\n",
    "Salary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92955e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8788ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6471275",
   "metadata": {},
   "source": [
    "### Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20dd24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9429df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting web driver\n",
    "driver= webdriver. Chrome(r'C:\\Users\\hifzu\\Downloads\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d4df734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking webpage to web driver\n",
    "link= \"https://www.flipkart.com\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "06949fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding text in  product search bar\n",
    "keyword= driver.find_element_by_xpath(\"//input[@title='Search for products, brands and more']\")\n",
    "keyword.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2a51dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on \"Search\"\n",
    "search= driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d1b3f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Brand Name:\n",
    "brand=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "Brand=[]\n",
    "for k in brand:\n",
    "    Brand.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3af13e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Product description:\n",
    "des=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "Des=[]\n",
    "for k in des:\n",
    "    Des.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "c497ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Price:\n",
    "price=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "Price=[]\n",
    "for k in price:\n",
    "    Price.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2e527d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Price Discount:\n",
    "disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "Disc=[]\n",
    "for k in disc:\n",
    "    Disc.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0baceb",
   "metadata": {},
   "source": [
    "Page 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e93fd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to nextpage:\n",
    "next = driver.find_element_by_xpath(\"//a[@class='ge-49M']\")\n",
    "next.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d0d5318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Brand name from page 2:\n",
    "brand2= driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "Brand2=[]\n",
    "for k in brand2:\n",
    "    Brand2.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c722d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Product description from page 2:\n",
    "des2=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "Des2=[]\n",
    "for k in des2:\n",
    "    Des2.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "74139c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Price from page 2:\n",
    "price2=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "Price2=[]\n",
    "for k in price2:\n",
    "    Price2.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "6008a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Price Discount from page 2:\n",
    "disc2=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "Disc2=[]\n",
    "for k in disc2:\n",
    "    Disc2.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fbf681",
   "metadata": {},
   "source": [
    "Page 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "fdfd15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to page3:\n",
    "next3 = driver.find_element_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "next3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "3bea4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Brand name from page 3:\n",
    "brand3= driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "Brand3=[]\n",
    "for k in brand3:\n",
    "    Brand3.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "663d7dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Product description from page 3:\n",
    "des3=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "Des3=[]\n",
    "for k in des3:\n",
    "    Des3.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "362079a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Price from page 3:\n",
    "price3=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "Price3=[]\n",
    "for k in price3:\n",
    "    Price3.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e582b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Price Discount from page 3:\n",
    "disc3=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "Disc3=[]\n",
    "for k in disc3:\n",
    "    Disc3.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319532f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "91aa7d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand-Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>₹198</td>\n",
       "      <td>88% off</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹237</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹329</td>\n",
       "      <td>86% off</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>₹284</td>\n",
       "      <td>89% off</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹237</td>\n",
       "      <td>85% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹377</td>\n",
       "      <td>84% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>₹284</td>\n",
       "      <td>81% off</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer, Wayfarer, Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>₹375</td>\n",
       "      <td>64% off</td>\n",
       "      <td>UV Protection Wayfarer, Rectangular Sunglasses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>₹230</td>\n",
       "      <td>82% off</td>\n",
       "      <td>UV Protection, Gradient Aviator Sunglasses (57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>₹495</td>\n",
       "      <td>67% off</td>\n",
       "      <td>UV Protection, Gradient Oval Sunglasses (58)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand-Name Price Discount  \\\n",
       "0    SHAAH COLLECTIONS  ₹198  88% off   \n",
       "1               PIRASO  ₹237  85% off   \n",
       "2            Elligator  ₹329  86% off   \n",
       "3       kingsunglasses  ₹284  89% off   \n",
       "4               PIRASO  ₹237  85% off   \n",
       "..                 ...   ...      ...   \n",
       "96           Elligator  ₹377  84% off   \n",
       "97      kingsunglasses  ₹284  81% off   \n",
       "98               NuVew  ₹375  64% off   \n",
       "99              GANSTA  ₹230  82% off   \n",
       "100             AISLIN  ₹495  67% off   \n",
       "\n",
       "                                           Description  \n",
       "0    UV Protection, Polarized, Mirrored Rectangular...  \n",
       "1                UV Protection Aviator Sunglasses (54)  \n",
       "2                  UV Protection Round Sunglasses (54)  \n",
       "3    Mirrored, UV Protection Wayfarer Sunglasses (F...  \n",
       "4                UV Protection Aviator Sunglasses (54)  \n",
       "..                                                 ...  \n",
       "96               UV Protection Aviator Sunglasses (55)  \n",
       "97   Mirrored, UV Protection Wayfarer, Wayfarer, Wa...  \n",
       "98   UV Protection Wayfarer, Rectangular Sunglasses...  \n",
       "99     UV Protection, Gradient Aviator Sunglasses (57)  \n",
       "100       UV Protection, Gradient Oval Sunglasses (58)  \n",
       "\n",
       "[101 rows x 4 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame:\n",
    "Sunglasses=pd.DataFrame({})\n",
    "Sunglasses['Brand-Name']=Brand+Brand2[:21]+Brand3\n",
    "Sunglasses['Price']=Price+Price2[:21]+Price3\n",
    "Sunglasses['Discount']=Disc+Disc2[:21]+Disc3\n",
    "Sunglasses['Description']=Des+Des2[:21]+Des3\n",
    "Sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b3f09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39af228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45013181",
   "metadata": {},
   "source": [
    "### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. from the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\n",
    "\n",
    "#### Scrape:\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "6a6c2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e79594ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting web driver\n",
    "driver= webdriver. Chrome(r'C:\\Users\\hifzu\\Downloads\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "5bfd474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking webpage to web driver\n",
    "link= \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d5120bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we click on all reviews option:\n",
    "search= driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "6bff874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists:\n",
    "Rating=[]\n",
    "Review=[]\n",
    "Freview=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "d47c3c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,15):\n",
    "    link=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=\"+str(i)\n",
    "    driver.get(link)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    rating=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    time.sleep(2)\n",
    "    for i in rating:\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    review=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    time.sleep(1)\n",
    "    for i in review:\n",
    "        Review.append(i.text)\n",
    "        \n",
    "    freview=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "    time.sleep(1)\n",
    "    for i in freview:\n",
    "        Freview.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "5c86b916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It’s an amazing product from apple and the cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>Looking so good 👍 😍 super 👌 stylish 😎 phone\\nC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>I just directly switch from iphone 6s to iphon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>After 1 month use I found camera quality best ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating              Summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5            Brilliant   \n",
       "96      4            Must buy!   \n",
       "97      5          Good choice   \n",
       "98      5            Wonderful   \n",
       "99      5     Perfect product!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  I have migrated from OP 7pro... and trust me, ...  \n",
       "96  It’s an amazing product from apple and the cam...  \n",
       "97  Looking so good 👍 😍 super 👌 stylish 😎 phone\\nC...  \n",
       "98  I just directly switch from iphone 6s to iphon...  \n",
       "99  After 1 month use I found camera quality best ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame:\n",
    "Attributes=pd.DataFrame({})\n",
    "Attributes[\"Rating\"]=Rating[:100]\n",
    "Attributes[\"Summary\"]=Review[:100]\n",
    "Attributes[\"Full Review\"]=Freview[:100]\n",
    "Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f960a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840c8519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5b24834",
   "metadata": {},
   "source": [
    "### Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "#### You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ddfb24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3e0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting web driver\n",
    "driver= webdriver. Chrome(r'C:\\Users\\hifzu\\Downloads\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdcd8614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking webpage to web driver\n",
    "link= \"https://www.flipkart.com\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31281fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding text in  product search bar\n",
    "keyword= driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "keyword.send_keys(\"sneekers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22a7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on search option:\n",
    "search= driver.find_element_by_xpath(\"//button[@type='submit']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d08b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list:\n",
    "Brand=[]\n",
    "Desc=[]\n",
    "Price=[]\n",
    "Dis=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b12c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping the Data:\n",
    "for i in range(1,4):\n",
    "    link2=\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\"+str(i)\n",
    "    driver.get(link2)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    brand=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:\n",
    "        Brand.append(i.text)\n",
    "        \n",
    "    desc=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    for i in desc:\n",
    "        Desc.append(i.text)\n",
    "        \n",
    "    price=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for i in price:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "    disc=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in disc:\n",
    "        Dis.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9935dd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹536</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Longwalk</td>\n",
       "      <td>Men Boxer Sneakers For Men</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Treadfit</td>\n",
       "      <td>Modern &amp; Trendy Collection Combo Pack of 02 Sh...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>Casual Sneakers White Shoes For Men And Boys S...</td>\n",
       "      <td>₹913</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>casual for men Sneakers For Men</td>\n",
       "      <td>₹1,400</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SHOEFLY</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹362</td>\n",
       "      <td>53% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jokatoo</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹445</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                               Product Descriptions   Price  \\\n",
       "0           Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...    ₹536   \n",
       "1   luxury fashion  Luxury Fashionable casual sneaker shoes Sneake...    ₹379   \n",
       "2         Longwalk                         Men Boxer Sneakers For Men    ₹236   \n",
       "3         ASTEROID  Original Luxury Branded Fashionable Men's Casu...    ₹499   \n",
       "4           BRUTON  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...    ₹474   \n",
       "..             ...                                                ...     ...   \n",
       "95        Treadfit  Modern & Trendy Collection Combo Pack of 02 Sh...    ₹299   \n",
       "96           SPARX  Casual Sneakers White Shoes For Men And Boys S...    ₹913   \n",
       "97            PUMA                    casual for men Sneakers For Men  ₹1,400   \n",
       "98         SHOEFLY  Super Stylish & Trendy Combo Pack of 02 Pairs ...    ₹362   \n",
       "99         Jokatoo  Luxury Fashionable casual sneaker shoes Sneake...    ₹445   \n",
       "\n",
       "   Discount  \n",
       "0   66% off  \n",
       "1   70% off  \n",
       "2   52% off  \n",
       "3   75% off  \n",
       "4   86% off  \n",
       "..      ...  \n",
       "95  52% off  \n",
       "96  51% off  \n",
       "97  60% off  \n",
       "98  53% off  \n",
       "99  49% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame:\n",
    "Sneekers=pd.DataFrame({})\n",
    "Sneekers[\"Brand Name\"]=Brand[:100]\n",
    "Sneekers[\"Product Descriptions\"]=Desc[:100]\n",
    "Sneekers[\"Price\"]=Price[:100]\n",
    "Sneekers[\"Discount\"]=Dis[:100]\n",
    "Sneekers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336732d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e2f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fb9dc0e",
   "metadata": {},
   "source": [
    "###  Q9. Scrape data of 100 Shoes from the link - https://www.myntra.com/shoes.\n",
    "#### Attributes to scrape(Price:6871-13578, Color:Black):\n",
    "1. Brand\n",
    "2. Description\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a05419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beb03bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting web driver\n",
    "driver= webdriver. Chrome(r'C:\\Users\\hifzu\\Downloads\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33179525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking webpage to web driver\n",
    "link= \"https://www.myntra.com/shoes\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4b1f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Price filter:\n",
    "price=driver.find_element_by_xpath(\"//html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]\")\n",
    "price.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3246f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Color filter:\n",
    "color= driver.find_element_by_xpath(\"//span[@data-colorhex='black']\")\n",
    "color.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "886c258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty Lists:\n",
    "Brand=[]\n",
    "Des=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81d1f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping the Data:\n",
    "for i in range(1,3):\n",
    "    link2=\"https://www.myntra.com/shoes?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A6871.0_13578.0_6871.0%20TO%2013578.0%2C6897.0_13595.0_6897.0%20TO%2013595.0\"+str(i)\n",
    "    driver.get(link2)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    brand=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "    for i in brand:\n",
    "        Brand.append(i.text)\n",
    "        \n",
    "    des=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    for i in des:\n",
    "        Des.append(i.text)\n",
    "        \n",
    "    price=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "    for i in price:\n",
    "        Price.append(i.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6283553a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Driving Shoes</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Printed Slip-On Sneakers</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Black Leather Loafers</td>\n",
       "      <td>Rs. 8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Velocity Nitro Running</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Women BMW M Motorsport Shoes</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Textured Leather Formal Loafers</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Sneakers</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Block Sandals</td>\n",
       "      <td>Rs. 10355Rs. 10900(5% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand Name                 Product Descriptions  \\\n",
       "0              ALDO                    Men Driving Shoes   \n",
       "1              Geox         Men Printed Slip-On Sneakers   \n",
       "2              Puma       Men Cell Fraction Fade Running   \n",
       "3         J.FONTINI            Men Black Leather Loafers   \n",
       "4              Puma           Men Velocity Nitro Running   \n",
       "..              ...                                  ...   \n",
       "95  PUMA Motorsport         Women BMW M Motorsport Shoes   \n",
       "96   ROSSO BRUNELLO           Men Leather Formal Loafers   \n",
       "97        J.FONTINI  Men Textured Leather Formal Loafers   \n",
       "98             ALDO                       Women Sneakers   \n",
       "99          Saint G                Leather Block Sandals   \n",
       "\n",
       "                         Price  \n",
       "0                    Rs. 11999  \n",
       "1                    Rs. 10999  \n",
       "2                     Rs. 6999  \n",
       "3                     Rs. 8490  \n",
       "4                    Rs. 10999  \n",
       "..                         ...  \n",
       "95                    Rs. 6999  \n",
       "96                   Rs. 11999  \n",
       "97                    Rs. 8990  \n",
       "98                   Rs. 11999  \n",
       "99  Rs. 10355Rs. 10900(5% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame:\n",
    "Shoes=pd.DataFrame({})\n",
    "Shoes[\"Brand Name\"]=Brand[:100]\n",
    "Shoes[\"Product Descriptions\"]=Des[:100]\n",
    "Shoes[\"Price\"]=Price[:100]\n",
    "Shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e884a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93914562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0118421",
   "metadata": {},
   "source": [
    "### Q10. Scrape 10 Laptop data from https://www.amazon.in/ with CPU filters as  “Intel Core i7” and “Intel Core i9” \n",
    "#### Scrape below attributes:\n",
    "1. Title\n",
    "2. Rating\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b46663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48132402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting web driver\n",
    "driver= webdriver. Chrome(r'C:\\Users\\hifzu\\Downloads\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76043c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking webpage to web driver\n",
    "link= \"https://www.amazon.in/\"\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb784016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feeding text in search bar:\n",
    "keyword= driver.find_element_by_xpath(\"//input[@id='twotabsearchtextbox']\")\n",
    "keyword.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "241dc0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the input text:\n",
    "search=driver.find_element_by_xpath(\"//input[@id='nav-search-submit-button']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6695bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating CPU filter “Intel Core i7”:\n",
    "i7= driver.find_element_by_xpath(\"//li[@aria-label='Intel Core i7']\")\n",
    "i7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3693d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating CPU filter “Intel Core i9”:\n",
    "i9= driver.find_element_by_xpath(\"//li[@aria-label='Intel Core i9']\")\n",
    "i9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90d505ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Title=[]\n",
    "Price=[]\n",
    "Rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5e0c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Product name :\n",
    "title=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "\n",
    "for k in title:\n",
    "    Title.append(k.text.replace('\\n',\"\"))\n",
    "    \n",
    "price=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for k in price:\n",
    "    Price.append(k.text.replace('\\n',\"\"))\n",
    "\n",
    "    \n",
    "rate=driver.find_elements_by_xpath(\"//span[@class='a-size-base']\")\n",
    "for k in rate:\n",
    "    Rating.append(k.text.replace('\\n',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "299714f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell XPS 9370 13.3-inch FHD Display Thin &amp; Lig...</td>\n",
       "      <td>11</td>\n",
       "      <td>1,14,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Envy 11th Gen Core i7 Processor 13.3-inch (...</td>\n",
       "      <td>231</td>\n",
       "      <td>1,23,350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>815</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad S540 11th Gen Intel Core i7 13....</td>\n",
       "      <td>101</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...</td>\n",
       "      <td>31</td>\n",
       "      <td>5,56,524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....</td>\n",
       "      <td>29</td>\n",
       "      <td>1,07,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 La...</td>\n",
       "      <td>4</td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>66</td>\n",
       "      <td>98,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...</td>\n",
       "      <td>19</td>\n",
       "      <td>1,13,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm...</td>\n",
       "      <td>2</td>\n",
       "      <td>74,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Brand Name Product Rating     Price\n",
       "0  Dell XPS 9370 13.3-inch FHD Display Thin & Lig...             11  1,14,990\n",
       "1  HP Envy 11th Gen Core i7 Processor 13.3-inch (...            231  1,23,350\n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i7-1...            815    57,990\n",
       "3  Lenovo IdeaPad S540 11th Gen Intel Core i7 13....            101    77,990\n",
       "4  ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...             31  5,56,524\n",
       "5  Fujitsu UH-X 11th Gen Intel Core i7 13.3” (33....             29  1,07,990\n",
       "6  HP Pavilion 13(2021) 11th Gen Intel Core i7 La...              4    92,990\n",
       "7  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...             66    98,500\n",
       "8  ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...             19  1,13,990\n",
       "9  MSI GF75 Thin, Intel i7-10750H, 17.3\" (43.9 cm...              2    74,990"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame:\n",
    "Laptop=pd.DataFrame({})\n",
    "Laptop[\"Brand Name\"]=Title[:10]\n",
    "Laptop[\"Product Rating\"]=Rating[:10]\n",
    "Laptop[\"Price\"]=Price[:10]\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce4a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e30fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57af00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebf5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae347e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
